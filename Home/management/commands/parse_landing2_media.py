"""
–ö–æ–º–∞–Ω–¥–∞ –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞ –º–µ–¥–∏–∞ —Ñ–∞–π–ª–æ–≤ –∏–∑ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–≥–æ —Å–∞–π—Ç–∞ —Å–∞–ª–æ–Ω–∞ –∫—Ä–∞—Å–æ—Ç—ã
–°–∫–∞—á–∏–≤–∞–µ—Ç –≤—Å–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –≤ media/landing2/
"""
import os
import re
import requests
from urllib.parse import urljoin, urlparse
from django.core.management.base import BaseCommand
from django.conf import settings
from pathlib import Path


class Command(BaseCommand):
    help = '–ü–∞—Ä—Å–∏–Ω–≥ –º–µ–¥–∏–∞ —Ñ–∞–π–ª–æ–≤ —Å –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–≥–æ —Å–∞–π—Ç–∞ —Å–∞–ª–æ–Ω–∞ –∫—Ä–∞—Å–æ—Ç—ã'

    def __init__(self):
        super().__init__()
        self.base_url = 'https://mos-263463.oml.ru/'
        self.media_dir = Path(settings.MEDIA_ROOT) / 'landing2'
        self.downloaded_files = {}
        
    def add_arguments(self, parser):
        parser.add_argument(
            '--force',
            action='store_true',
            help='–ü–µ—Ä–µ–∑–∞–ø–∏—Å–∞—Ç—å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ —Ñ–∞–π–ª—ã',
        )

    def handle(self, *args, **options):
        force = options.get('force', False)
        
        self.stdout.write(self.style.SUCCESS('üöÄ –ù–∞—á–∏–Ω–∞–µ–º –ø–∞—Ä—Å–∏–Ω–≥ –º–µ–¥–∏–∞ —Ñ–∞–π–ª–æ–≤...'))
        
        # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
        self.create_directories()
        
        # –°–∫–∞—á–∏–≤–∞–µ–º HTML —Å—Ç—Ä–∞–Ω–∏—Ü—ã
        self.stdout.write('üìÑ –ó–∞–≥—Ä—É–∂–∞–µ–º HTML...')
        html_content = self.download_html()
        
        if not html_content:
            self.stdout.write(self.style.ERROR('‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å HTML'))
            return
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –≤—Å–µ URL –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
        self.stdout.write('üîç –ò—â–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è...')
        image_urls = self.extract_image_urls(html_content)
        
        self.stdout.write(f'‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(image_urls)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π')
        
        # –°–∫–∞—á–∏–≤–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        self.stdout.write('‚¨áÔ∏è  –°–∫–∞—á–∏–≤–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è...')
        downloaded = 0
        skipped = 0
        
        for url in image_urls:
            if self.download_image(url, force):
                downloaded += 1
            else:
                skipped += 1
            
            # –ü—Ä–æ–≥—Ä–µ—Å—Å
            total = downloaded + skipped
            if total % 5 == 0:
                self.stdout.write(f'   –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {total}/{len(image_urls)}')
        
        self.stdout.write(self.style.SUCCESS(f'\n‚úÖ –ü–∞—Ä—Å–∏–Ω–≥ –∑–∞–≤–µ—Ä—à–µ–Ω!'))
        self.stdout.write(f'   –°–∫–∞—á–∞–Ω–æ: {downloaded}')
        self.stdout.write(f'   –ü—Ä–æ–ø—É—â–µ–Ω–æ: {skipped}')
        self.stdout.write(f'   –ü–∞–ø–∫–∞: {self.media_dir}')
        
        # –°–æ–∑–¥–∞–µ–º mapping —Ñ–∞–π–ª
        self.create_mapping_file()
        
    def create_directories(self):
        """–°–æ–∑–¥–∞–µ—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏"""
        dirs = ['images', 'portfolio', 'team', 'brands', 'icons', 'backgrounds']
        for dir_name in dirs:
            dir_path = self.media_dir / dir_name
            dir_path.mkdir(parents=True, exist_ok=True)
        self.stdout.write(self.style.SUCCESS('‚úÖ –î–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ —Å–æ–∑–¥–∞–Ω—ã'))
    
    def download_html(self):
        """–°–∫–∞—á–∏–≤–∞–µ—Ç HTML —Å—Ç—Ä–∞–Ω–∏—Ü—É"""
        try:
            response = requests.get(self.base_url, timeout=30)
            response.raise_for_status()
            return response.text
        except Exception as e:
            self.stdout.write(self.style.ERROR(f'–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ HTML: {e}'))
            return None
    
    def extract_image_urls(self, html):
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –≤—Å–µ URL –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∏–∑ HTML"""
        image_urls = set()
        
        # –ò—â–µ–º img src
        img_pattern = r'<img[^>]+src=["\'](https?://[^"\']+)["\']'
        for match in re.finditer(img_pattern, html):
            image_urls.add(match.group(1))
        
        # –ò—â–µ–º background-image –≤ style
        bg_pattern = r'background-image:\s*url\(["\']?(https?://[^"\')\s]+)["\']?\)'
        for match in re.finditer(bg_pattern, html):
            image_urls.add(match.group(1))
        
        # –ò—â–µ–º –≤ inline styles
        inline_pattern = r'style=["\']([^"\']*background-image:[^"\']*)["\']'
        for match in re.finditer(inline_pattern, html):
            style_content = match.group(1)
            bg_urls = re.findall(r'url\(["\']?(https?://[^"\')\s]+)["\']?\)', style_content)
            image_urls.update(bg_urls)
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–µ –ø—É—Ç–∏ –≤ –∞–±—Å–æ–ª—é—Ç–Ω—ã–µ
        absolute_urls = []
        for url in image_urls:
            if url.startswith('http'):
                absolute_urls.append(url)
            else:
                absolute_urls.append(urljoin(self.base_url, url))
        
        return list(set(absolute_urls))
    
    def download_image(self, url, force=False):
        """–°–∫–∞—á–∏–≤–∞–µ—Ç –æ–¥–Ω–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ"""
        try:
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∏–º—è —Ñ–∞–π–ª–∞
            parsed = urlparse(url)
            filename = os.path.basename(parsed.path)
            
            if not filename or '.' not in filename:
                # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∏–º—è –∏–∑ —Ö—ç—à–∞ URL
                import hashlib
                filename = hashlib.md5(url.encode()).hexdigest()[:10] + '.jpg'
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏—é –ø–æ URL
            category = self.categorize_image(url, filename)
            filepath = self.media_dir / category / filename
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ
            if filepath.exists() and not force:
                self.downloaded_files[url] = str(filepath.relative_to(settings.MEDIA_ROOT))
                return False
            
            # –°–∫–∞—á–∏–≤–∞–µ–º
            response = requests.get(url, timeout=15, stream=True)
            response.raise_for_status()
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º
            with open(filepath, 'wb') as f:
                for chunk in response.iter_content(chunk_size=8192):
                    f.write(chunk)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–∞–ø–ø–∏–Ω–≥
            self.downloaded_files[url] = str(filepath.relative_to(settings.MEDIA_ROOT))
            
            return True
            
        except Exception as e:
            self.stdout.write(self.style.WARNING(f'‚ö†Ô∏è  –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ {url}: {e}'))
            return False
    
    def categorize_image(self, url, filename):
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –∫–∞—Ç–µ–≥–æ—Ä–∏—é –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –ø–æ URL –∏–ª–∏ –∏–º–µ–Ω–∏"""
        url_lower = url.lower()
        filename_lower = filename.lower()
        
        if any(x in url_lower or x in filename_lower for x in ['portfolio', 'work', 'result']):
            return 'portfolio'
        elif any(x in url_lower or x in filename_lower for x in ['team', 'master', 'specialist']):
            return 'team'
        elif any(x in url_lower or x in filename_lower for x in ['brand', 'logo', 'partner']):
            return 'brands'
        elif any(x in url_lower or x in filename_lower for x in ['icon', 'ico']):
            return 'icons'
        elif any(x in url_lower or x in filename_lower for x in ['background', 'bg', 'hero']):
            return 'backgrounds'
        else:
            return 'images'
    
    def create_mapping_file(self):
        """–°–æ–∑–¥–∞–µ—Ç —Ñ–∞–π–ª –º–∞–ø–ø–∏–Ω–≥–∞ —Å—Ç–∞—Ä—ã—Ö URL –Ω–∞ –Ω–æ–≤—ã–µ –ø—É—Ç–∏"""
        mapping_file = self.media_dir / 'url_mapping.txt'
        
        with open(mapping_file, 'w', encoding='utf-8') as f:
            f.write('# –ú–∞–ø–ø–∏–Ω–≥ URL –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π\n')
            f.write('# –§–æ—Ä–º–∞—Ç: –°–¢–ê–†–´–ô_URL -> –ù–û–í–´–ô_–ü–£–¢–¨\n\n')
            
            for old_url, new_path in sorted(self.downloaded_files.items()):
                f.write(f'{old_url} -> {new_path}\n')
        
        self.stdout.write(self.style.SUCCESS(f'‚úÖ –°–æ–∑–¥–∞–Ω —Ñ–∞–π–ª –º–∞–ø–ø–∏–Ω–≥–∞: {mapping_file}'))

