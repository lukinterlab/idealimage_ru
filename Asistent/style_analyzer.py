"""
–ê–Ω–∞–ª–∏–∑ —Å—Ç–∏–ª—è –Ω–∞–ø–∏—Å–∞–Ω–∏—è —Å—Ç–∞—Ç–µ–π –Ω–∞ —Å–∞–π—Ç–µ
–ò–∑–≤–ª–µ–∫–∞–µ—Ç –ø–∞—Ç—Ç–µ—Ä–Ω—ã: –¥–ª–∏–Ω–∞, —Å—Ç—Ä—É–∫—Ç—É—Ä–∞, —Ç–æ–Ω, —ç–º–æ–¥–∑–∏, –∑–∞–≥–æ–ª–æ–≤–∫–∏
"""
import re
import logging
from typing import List, Dict
from django.db.models import QuerySet

logger = logging.getLogger(__name__)


class StyleAnalyzer:
    """–ê–Ω–∞–ª–∏–∑ —Å—Ç–∏–ª—è —Å—Ç–∞—Ç–µ–π"""
    
    def analyze_posts(self, posts: QuerySet) -> str:
        """
        –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Å—Ç–∏–ª—å –∫–æ–ª–ª–µ–∫—Ü–∏–∏ —Å—Ç–∞—Ç–µ–π
        
        Args:
            posts: QuerySet —Å –ø–æ—Å—Ç–∞–º–∏
        
        Returns:
            –°—Ç—Ä–æ–∫–∞ —Å –æ–ø–∏—Å–∞–Ω–∏–µ–º —Å—Ç–∏–ª—è –¥–ª—è –ø—Ä–æ–º–ø—Ç–∞
        """
        logger.info(f"üìñ –ê–Ω–∞–ª–∏–∑ —Å—Ç–∏–ª—è {posts.count()} —Å—Ç–∞—Ç–µ–π...")
        
        if not posts.exists():
            return "–°—Ç–∏–ª—å: –î—Ä—É–∂–µ–ª—é–±–Ω—ã–π, –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–π, —Å —ç–º–æ–¥–∑–∏. –ó–∞–≥–æ–ª–æ–≤–∫–∏ —Å —Ü–∏—Ñ—Ä–∞–º–∏."
        
        stats = {
            'word_counts': [],
            'has_emojis': 0,
            'has_lists': 0,
            'has_headings': 0,
            'has_images': 0,
            'avg_paragraph_length': [],
            'tone_indicators': {
                'friendly': 0,  # –≤—ã, –≤–∞—à, –¥—Ä—É–∑—å—è
                'formal': 0,    # –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ, —Å–ª–µ–¥—É–µ—Ç, —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è
                'casual': 0,    # –∫–ª–∞—Å—Å–Ω–æ, –∫—Ä—É—Ç–æ, —Å—É–ø–µ—Ä
            }
        }
        
        for post in posts:
            content = post.content
            
            # –ü–æ–¥—Å—á–µ—Ç —Å–ª–æ–≤
            words = len(content.split())
            stats['word_counts'].append(words)
            
            # –≠–º–æ–¥–∑–∏
            emoji_pattern = re.compile(r'[\U0001F300-\U0001F9FF]|[\u2600-\u26FF]|[\u2700-\u27BF]')
            if emoji_pattern.search(content):
                stats['has_emojis'] += 1
            
            # –°–ø–∏—Å–∫–∏
            if '<ul>' in content or '<ol>' in content or re.search(r'^\d+\.', content, re.MULTILINE):
                stats['has_lists'] += 1
            
            # –ó–∞–≥–æ–ª–æ–≤–∫–∏
            if '<h2>' in content or '<h3>' in content:
                stats['has_headings'] += 1
            
            # –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            if '<img' in content or hasattr(post, 'images') and post.images.exists():
                stats['has_images'] += 1
            
            # –î–ª–∏–Ω–∞ –ø–∞—Ä–∞–≥—Ä–∞—Ñ–æ–≤
            paragraphs = re.findall(r'<p>(.+?)</p>', content)
            if paragraphs:
                avg_p_len = sum(len(p.split()) for p in paragraphs) / len(paragraphs)
                stats['avg_paragraph_length'].append(avg_p_len)
            
            # –¢–æ–Ω
            content_lower = content.lower()
            if any(word in content_lower for word in ['–≤—ã', '–≤–∞—à', '–¥—Ä—É–∑—å—è', '–ø–æ–¥–µ–ª–∏–º—Å—è']):
                stats['tone_indicators']['friendly'] += 1
            if any(word in content_lower for word in ['–Ω–µ–æ–±—Ö–æ–¥–∏–º–æ', '—Å–ª–µ–¥—É–µ—Ç', '—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è', '–≤–∞–∂–Ω–æ']):
                stats['tone_indicators']['formal'] += 1
            if any(word in content_lower for word in ['–∫–ª–∞—Å—Å–Ω–æ', '–∫—Ä—É—Ç–æ', '—Å—É–ø–µ—Ä', '–æ–±–∞–ª–¥–µ—Ç—å']):
                stats['tone_indicators']['casual'] += 1
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –æ–ø–∏—Å–∞–Ω–∏–µ —Å—Ç–∏–ª—è
        total = posts.count()
        
        # –°—Ä–µ–¥–Ω—è—è –¥–ª–∏–Ω–∞
        avg_words = sum(stats['word_counts']) / len(stats['word_counts']) if stats['word_counts'] else 800
        
        # –¢–æ–Ω
        tone_scores = stats['tone_indicators']
        dominant_tone = max(tone_scores, key=tone_scores.get)
        tone_map = {
            'friendly': '–¥—Ä—É–∂–µ–ª—é–±–Ω—ã–π, –æ–±—Ä–∞—â–µ–Ω–∏–µ –Ω–∞ "–≤—ã"',
            'formal': '—Ñ–æ—Ä–º–∞–ª—å–Ω—ã–π, —ç–∫—Å–ø–µ—Ä—Ç–Ω—ã–π',
            'casual': '–Ω–µ—Ñ–æ—Ä–º–∞–ª—å–Ω—ã–π, —Ä–∞–∑–≥–æ–≤–æ—Ä–Ω—ã–π'
        }
        tone_desc = tone_map.get(dominant_tone, '–Ω–µ–π—Ç—Ä–∞–ª—å–Ω—ã–π')
        
        # –°—Ç—Ä—É–∫—Ç—É—Ä–Ω—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã
        structural_features = []
        if stats['has_emojis'] > total * 0.5:
            structural_features.append("—ç–º–æ–¥–∑–∏ –≤ –∑–∞–≥–æ–ª–æ–≤–∫–∞—Ö –∏ —Ç–µ–∫—Å—Ç–µ")
        if stats['has_lists'] > total * 0.6:
            structural_features.append("–Ω—É–º–µ—Ä–æ–≤–∞–Ω–Ω—ã–µ —Å–ø–∏—Å–∫–∏ –∏ –±—É–ª–ª–∏—Ç—ã")
        if stats['has_headings'] > total * 0.7:
            structural_features.append("–ø–æ–¥–∑–∞–≥–æ–ª–æ–≤–∫–∏ H2, H3")
        if stats['has_images'] > total * 0.5:
            structural_features.append("–∏–ª–ª—é—Å—Ç—Ä–∞—Ü–∏–∏ –∏ —Ñ–æ—Ç–æ")
        
        # –°—Ä–µ–¥–Ω—è—è –¥–ª–∏–Ω–∞ –ø–∞—Ä–∞–≥—Ä–∞—Ñ–∞
        avg_p = sum(stats['avg_paragraph_length']) / len(stats['avg_paragraph_length']) if stats['avg_paragraph_length'] else 40
        paragraph_style = "–∫–æ—Ä–æ—Ç–∫–∏–µ –ø–∞—Ä–∞–≥—Ä–∞—Ñ—ã (2-3 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è)" if avg_p < 50 else "—Å—Ä–µ–¥–Ω–∏–µ –ø–∞—Ä–∞–≥—Ä–∞—Ñ—ã (4-6 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π)"
        
        # –ò—Ç–æ–≥–æ–≤–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ
        style_guide = f"""–°—Ç–∏–ª—å —Å–∞–π—Ç–∞ (–Ω–∞ –æ—Å–Ω–æ–≤–µ {total} —Å—Ç–∞—Ç–µ–π):

üìä –°–¢–†–£–ö–¢–£–†–ê:
- –î–ª–∏–Ω–∞: {int(avg_words)} —Å–ª–æ–≤ ({int(avg_words * 0.8)}-{int(avg_words * 1.2)} –¥–∏–∞–ø–∞–∑–æ–Ω)
- –ü–∞—Ä–∞–≥—Ä–∞—Ñ—ã: {paragraph_style}
- –≠–ª–µ–º–µ–Ω—Ç—ã: {', '.join(structural_features) if structural_features else '–ø—Ä–æ—Å—Ç–æ–π —Ç–µ–∫—Å—Ç'}

üé≠ –¢–û–ù:
- {tone_desc.capitalize()}
- –ß–∏—Ç–∞—Ç–µ–ª—é: –æ–±—Ä–∞—â–µ–Ω–∏–µ –Ω–∞ "–≤—ã", –ª–∏—á–Ω—ã–µ –æ–±—Ä–∞—â–µ–Ω–∏—è
- –°—Ç–∏–ª—å: –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–π —Å –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–º–∏ —Å–æ–≤–µ—Ç–∞–º–∏

üìù –û–§–û–†–ú–õ–ï–ù–ò–ï:
- –ó–∞–≥–æ–ª–æ–≤–∫–∏: {"—Å —ç–º–æ–¥–∑–∏" if stats['has_emojis'] > total * 0.5 else "–±–µ–∑ —ç–º–æ–¥–∑–∏"}
- –°–ø–∏—Å–∫–∏: {"—á–∞—Å—Ç–æ –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è" if stats['has_lists'] > total * 0.5 else "—Ä–µ–¥–∫–æ"}
- –í—ã–¥–µ–ª–µ–Ω–∏—è: —Ü–∏—Ç–∞—Ç—ã, blockquote –¥–ª—è –≤–∞–∂–Ω—ã—Ö –º—ã—Å–ª–µ–π

‚úÖ –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò:
- –ò—Å–ø–æ–ª—å–∑—É–π —Å—Ç—Ä—É–∫—Ç—É—Ä—É –∫–∞–∫ –≤ –ø—Ä–∏–º–µ—Ä–∞—Ö –≤—ã—à–µ
- –°–æ—Ö—Ä–∞–Ω—è–π –¥—Ä—É–∂–µ–ª—é–±–Ω—ã–π –Ω–æ —ç–∫—Å–ø–µ—Ä—Ç–Ω—ã–π —Ç–æ–Ω
- –î–æ–±–∞–≤–ª—è–π –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ —Å–æ–≤–µ—Ç—ã –∏ –ø—Ä–∏–º–µ—Ä—ã
- –ü–∏—à–∏ –∂–∏–≤—ã–º —Ä—É—Å—Å–∫–∏–º —è–∑—ã–∫–æ–º –±–µ–∑ —à—Ç–∞–º–ø–æ–≤"""
        
        logger.info(f"‚úÖ –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à—ë–Ω: {int(avg_words)} —Å–ª–æ–≤, —Ç–æ–Ω={dominant_tone}")
        
        return style_guide
    
    def analyze_author_style(self, author, limit=10):
        """
        –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Å—Ç–∏–ª—å –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –∞–≤—Ç–æ—Ä–∞
        
        Args:
            author: –û–±—ä–µ–∫—Ç User (–∞–≤—Ç–æ—Ä)
            limit: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö —Å—Ç–∞—Ç–µ–π –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
        
        Returns:
            Dict —Å –∞–Ω–∞–ª–∏–∑–æ–º —Å—Ç–∏–ª—è –∞–≤—Ç–æ—Ä–∞
        """
        from blog.models import Post
        
        logger.info(f"üîç –ê–Ω–∞–ª–∏–∑ —Å—Ç–∏–ª—è –∞–≤—Ç–æ—Ä–∞: {author.username}")
        
        # –ü–æ–ª—É—á–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ —Å—Ç–∞—Ç—å–∏ –∞–≤—Ç–æ—Ä–∞
        posts = Post.objects.filter(
            author=author,
            status='published'
        ).order_by('-created')[:limit]
        
        if not posts.exists():
            logger.warning(f"‚ö†Ô∏è –£ –∞–≤—Ç–æ—Ä–∞ {author.username} –Ω–µ—Ç –æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–Ω—ã—Ö —Å—Ç–∞—Ç–µ–π")
            return {
                'style_description': '–°—Ç–∏–ª—å: –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–π, –¥—Ä—É–∂–µ–ª—é–±–Ω—ã–π, —Å –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–º–∏ —Å–æ–≤–µ—Ç–∞–º–∏',
                'avg_word_count': 1000,
                'tone': 'friendly',
                'use_emojis': True,
                'use_lists': True
            }
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –º–µ—Ç–æ–¥ analyze_posts
        style_guide = self.analyze_posts(posts)
        
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –≤ —Ñ–æ—Ä–º–∞—Ç–µ —Å–ª–æ–≤–∞—Ä—è –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ –ø—Ä–æ–º–ø—Ç–µ
        return {
            'style_description': style_guide,
            'author_name': author.username,
            'analyzed_posts_count': posts.count()
        }